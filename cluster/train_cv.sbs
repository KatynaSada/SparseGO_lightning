#!/bin/bash
#SBATCH --partition=general
#SBATCH --qos=regular
#SBATCH --job-name=ðŸ§¬train_cv #ðŸ¦ train_cv_fake ðŸš€train_cv_final 
#SBATCH --gres=gpu:4
#SBATCH --ntasks-per-node=4 # This needs to match Trainer(devices=...), must be number of gpus
#SBATCH --constraint=a100-sxm4 # --constraint=rtx3090
#SBATCH --mem=100gb
#SBATCH --nodes=1 # This needs to match Trainer(num_nodes=...)
#SBATCH --cpus-per-task=4 # total cpus = cpus-per-task*ntasks-per-node
#SBATCH --output=/scratch/ksada/train_cv.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=ksada@unav.es
 
echo `date`
module load Python
hostname

export WANDB_CACHE_DIR=/scratch/ksada/.cache

cd /scratch/ksada/SparseGO_lightning/cluster

# Call the shell script to execute the training
sh /scratch/ksada/SparseGO_lightning/cluster/train_cv.sh # train_cv_fake

